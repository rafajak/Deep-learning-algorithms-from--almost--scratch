{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#in the spirit of deliberate practice - quick, simple neural networks in numpy and pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple neural network in Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "num_epochs = 500 \n",
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1  (1000, 100)\n",
      "w2  (100, 10)\n",
      "29414411.3186713\n",
      "1099705.2768119196\n",
      "211037.44761508633\n",
      "70235.94668430273\n",
      "28027.216459783405\n",
      "12469.514320050472\n",
      "5962.416360799567\n",
      "2999.780167489182\n",
      "1567.8145078102823\n",
      "843.4173140663796\n",
      "463.93586302743176\n",
      "259.6903470343769\n",
      "147.37902143053935\n",
      "84.57018543881539\n",
      "48.96687076005258\n",
      "28.576892328839325\n",
      "16.798655862462528\n",
      "9.928519696568767\n",
      "5.89412205934819\n",
      "3.512636725524398\n",
      "2.100055174395472\n",
      "1.2590331442792155\n",
      "0.7566041897175123\n",
      "0.4556297135862935\n",
      "0.27485914457381566\n",
      "0.16607879270225273\n",
      "0.10048329792133362\n",
      "0.060870186235282606\n",
      "0.03691374226220619\n",
      "0.02240631241478453\n",
      "0.013611750673269307\n",
      "0.008275214594386064\n",
      "0.005034530616264805\n",
      "0.003064705010738344\n",
      "0.0018666079850745735\n",
      "0.0011374293756767362\n",
      "0.0006933988233606237\n",
      "0.00042289882288744043\n",
      "0.0002580126832501718\n",
      "0.00015747054537804104\n",
      "9.613747003442844e-05\n",
      "5.870735705237897e-05\n",
      "3.586069252056624e-05\n",
      "2.1910630848374097e-05\n",
      "1.3390155796755289e-05\n",
      "8.184729071241584e-06\n",
      "5.004040355504139e-06\n",
      "3.0599090909543413e-06\n",
      "1.871463401523879e-06\n",
      "1.144795941736375e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define training and test data\n",
    "\n",
    "x = np.random.randn(N,D_in)\n",
    "y = np.random.randn(N,D_out)\n",
    "\n",
    "w1 = np.random.randn(D_in,H)\n",
    "w2 = np.random.randn(H,D_out)\n",
    "\n",
    "print(\"w1 \",w1.shape)\n",
    "print(\"w2 \",w2.shape)\n",
    "\n",
    "# training\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    h1_out = np.dot(x,w1)\n",
    "    h1_relu = np.maximum(0,h1_out)\n",
    "    predictions = np.dot(h1_relu,w2)\n",
    "    \n",
    "    loss = np.square(predictions - y).sum()  #the sum is to get an single float from the matrix of losses\n",
    "\n",
    "    # backward prop\n",
    "    # e.g. grad_w2 is a derivative of the loss in respect to weight matrix w2\n",
    "    \n",
    "    grad_predictions = 2*(predictions - y)\n",
    "    grad_w2 = np.dot(h1_relu.T,grad_predictions)\n",
    "    grad_h1_relu = grad_predictions.dot(w2.T)\n",
    "   \n",
    "    grad_h1_out = grad_h1_relu.copy() #derivative of relu is essentially relu (for x=0 it's undefined, but we assume it's 0)\n",
    "    grad_h1_out[h1_out <= 0] = 0 # applying relu in backprop\n",
    "    \n",
    "    grad_w1 = x.T.dot(grad_h1_out)\n",
    "#     grad_w1 = x.T.dot(grad_h1_out).dot(w2).dot(grad_predictions.T)\n",
    "\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def print_name_and_shape(*args):       \n",
    "#     for a in args:\n",
    "#         print(a.shape)\n",
    "\n",
    "# print_name_and_shape(x,grad_h1_out,w2,grad_predictions)\n",
    "# x(64, 1000).T.dot(grad_h1_out(64, 100)).dot(w2(100, 10)).dot((grad_predictions.T(64, 10)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try the same simple neural network using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28985856.0\n",
      "1640550.25\n",
      "207463.6875\n",
      "63563.81640625\n",
      "23489.7734375\n",
      "9714.9619140625\n",
      "4304.44482421875\n",
      "2000.4896240234375\n",
      "961.68603515625\n",
      "474.29949951171875\n",
      "238.7459716796875\n",
      "122.19041442871094\n",
      "63.431182861328125\n",
      "33.33958435058594\n",
      "17.71767234802246\n",
      "9.509765625\n",
      "5.1505866050720215\n",
      "2.8126845359802246\n",
      "1.5474971532821655\n",
      "0.8572564125061035\n",
      "0.47791704535484314\n",
      "0.2679431140422821\n",
      "0.15101556479930878\n",
      "0.08553207665681839\n",
      "0.04867009446024895\n",
      "0.027826018631458282\n",
      "0.016010185703635216\n",
      "0.009279963560402393\n",
      "0.005453635938465595\n",
      "0.003264279803261161\n",
      "0.0020070511382073164\n",
      "0.0012695626355707645\n",
      "0.0008290941477753222\n",
      "0.0005621450254693627\n",
      "0.00039145012851804495\n",
      "0.0002825604460667819\n",
      "0.00021122126781847328\n",
      "0.00016217672964558005\n",
      "0.0001274686655960977\n",
      "0.00010205388389294967\n",
      "8.315987361129373e-05\n",
      "6.897183629916981e-05\n",
      "5.8087865909328684e-05\n",
      "4.934201933792792e-05\n",
      "4.2869291064562276e-05\n",
      "3.7077959859743714e-05\n",
      "3.236733755329624e-05\n",
      "2.895282523240894e-05\n",
      "2.5945026209228672e-05\n",
      "2.3594007870997302e-05\n"
     ]
    }
   ],
   "source": [
    "# define training and test data\n",
    "\n",
    "x = torch.autograd.Variable(torch.randn(N,D_in), requires_grad=False)\n",
    "y = torch.autograd.Variable(torch.randn(N,D_out), requires_grad=False)\n",
    "\n",
    "w1 = torch.autograd.Variable(torch.randn(D_in,H), requires_grad=True)\n",
    "w2 = torch.autograd.Variable(torch.randn(H,D_out), requires_grad=True)\n",
    "\n",
    "\n",
    "# training\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    h1_out = x.mm(w1) # 64,100\n",
    "    h1_relu = torch.clamp(h1_out,0) #not sure this actually works\n",
    "    predictions = torch.mm(h1_relu, w2)\n",
    "    \n",
    "    loss = torch.pow(predictions - y, 2).sum()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(loss.item())\n",
    "    \n",
    "    #backprop\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "    w1.grad.zero_()\n",
    "    w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

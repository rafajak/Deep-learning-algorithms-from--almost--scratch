{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#in the spirit of deliberate practice - quick, simple neural networks in numpy and pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple neural network in Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "num_epochs = 500 \n",
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1  (1000, 100)\n",
      "w2  (100, 10)\n",
      "29414411.3186713\n",
      "1099705.2768119196\n",
      "211037.44761508633\n",
      "70235.94668430273\n",
      "28027.216459783405\n",
      "12469.514320050472\n",
      "5962.416360799567\n",
      "2999.780167489182\n",
      "1567.8145078102823\n",
      "843.4173140663796\n",
      "463.93586302743176\n",
      "259.6903470343769\n",
      "147.37902143053935\n",
      "84.57018543881539\n",
      "48.96687076005258\n",
      "28.576892328839325\n",
      "16.798655862462528\n",
      "9.928519696568767\n",
      "5.89412205934819\n",
      "3.512636725524398\n",
      "2.100055174395472\n",
      "1.2590331442792155\n",
      "0.7566041897175123\n",
      "0.4556297135862935\n",
      "0.27485914457381566\n",
      "0.16607879270225273\n",
      "0.10048329792133362\n",
      "0.060870186235282606\n",
      "0.03691374226220619\n",
      "0.02240631241478453\n",
      "0.013611750673269307\n",
      "0.008275214594386064\n",
      "0.005034530616264805\n",
      "0.003064705010738344\n",
      "0.0018666079850745735\n",
      "0.0011374293756767362\n",
      "0.0006933988233606237\n",
      "0.00042289882288744043\n",
      "0.0002580126832501718\n",
      "0.00015747054537804104\n",
      "9.613747003442844e-05\n",
      "5.870735705237897e-05\n",
      "3.586069252056624e-05\n",
      "2.1910630848374097e-05\n",
      "1.3390155796755289e-05\n",
      "8.184729071241584e-06\n",
      "5.004040355504139e-06\n",
      "3.0599090909543413e-06\n",
      "1.871463401523879e-06\n",
      "1.144795941736375e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define training and test data\n",
    "\n",
    "x = np.random.randn(N,D_in)\n",
    "y = np.random.randn(N,D_out)\n",
    "\n",
    "w1 = np.random.randn(D_in,H)\n",
    "w2 = np.random.randn(H,D_out)\n",
    "\n",
    "print(\"w1 \",w1.shape)\n",
    "print(\"w2 \",w2.shape)\n",
    "\n",
    "# training\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    h1_out = np.dot(x,w1)\n",
    "    h1_relu = np.maximum(0,h1_out)\n",
    "    predictions = np.dot(h1_relu,w2)\n",
    "    \n",
    "    loss = np.square(predictions - y).sum()  #the sum is to get an single float from the matrix of losses\n",
    "\n",
    "    # backward prop\n",
    "    # e.g. grad_w2 is a derivative of the loss in respect to weight matrix w2\n",
    "    \n",
    "    grad_predictions = 2*(predictions - y)\n",
    "    grad_w2 = np.dot(h1_relu.T,grad_predictions)\n",
    "    grad_h1_relu = grad_predictions.dot(w2.T)\n",
    "   \n",
    "    grad_h1_out = grad_h1_relu.copy() #derivative of relu is essentially relu (for x=0 it's undefined, but we assume it's 0)\n",
    "    grad_h1_out[h1_out <= 0] = 0 # applying relu in backprop\n",
    "    \n",
    "    grad_w1 = x.T.dot(grad_h1_out)\n",
    "#     grad_w1 = x.T.dot(grad_h1_out).dot(w2).dot(grad_predictions.T)\n",
    "\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def print_name_and_shape(*args):       \n",
    "#     for a in args:\n",
    "#         print(a.shape)\n",
    "\n",
    "# print_name_and_shape(x,grad_h1_out,w2,grad_predictions)\n",
    "# x(64, 1000).T.dot(grad_h1_out(64, 100)).dot(w2(100, 10)).dot((grad_predictions.T(64, 10)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try the same simple neural network using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40337560.0\n",
      "1114492.25\n",
      "257671.359375\n",
      "92247.703125\n",
      "39567.12890625\n",
      "18807.6796875\n",
      "9537.228515625\n",
      "5067.7353515625\n",
      "2792.688720703125\n",
      "1582.8270263671875\n",
      "918.08544921875\n",
      "542.9712524414062\n",
      "326.52789306640625\n",
      "199.17181396484375\n",
      "123.00042724609375\n",
      "76.78062438964844\n",
      "48.38643264770508\n",
      "30.74588966369629\n",
      "19.681882858276367\n",
      "12.681753158569336\n",
      "8.21949291229248\n",
      "5.355597019195557\n",
      "3.506243944168091\n",
      "2.305366039276123\n",
      "1.521742343902588\n",
      "1.0080530643463135\n",
      "0.6700431704521179\n",
      "0.44664689898490906\n",
      "0.2986682951450348\n",
      "0.20014753937721252\n",
      "0.13446134328842163\n",
      "0.09057148545980453\n",
      "0.061124276369810104\n",
      "0.04135604202747345\n",
      "0.028059158474206924\n",
      "0.019085630774497986\n",
      "0.013049609959125519\n",
      "0.008977129124104977\n",
      "0.006221895106136799\n",
      "0.004367586225271225\n",
      "0.003104274393990636\n",
      "0.00224212440662086\n",
      "0.0016484413063153625\n",
      "0.0012329440796747804\n",
      "0.0009398906258866191\n",
      "0.0007280685240402818\n",
      "0.0005728733958676457\n",
      "0.0004580894601531327\n",
      "0.00037230856833048165\n",
      "0.0003048597718589008\n"
     ]
    }
   ],
   "source": [
    "# define training and test data\n",
    "\n",
    "x = torch.tensor(torch.randn(N,D_in), requires_grad=False)\n",
    "y = torch.tensor(torch.randn(N,D_out), requires_grad=False)\n",
    "\n",
    "w1 = torch.tensor(torch.randn(D_in,H), requires_grad=True)\n",
    "w2 = torch.tensor(torch.randn(H,D_out), requires_grad=True)\n",
    "\n",
    "\n",
    "# training\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    h1_out = x.mm(w1) # 64,100\n",
    "    h1_relu = torch.clamp(h1_out,0) #not sure this actually works\n",
    "    predictions = torch.mm(h1_relu, w2)\n",
    "    \n",
    "    loss = torch.pow(predictions - y, 2).sum()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(loss.item())\n",
    "    \n",
    "    #backprop\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "    w1.grad.zero_()\n",
    "    w2.grad.zero_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
